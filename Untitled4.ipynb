{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxhRAT59yZ3lBocQHnrKln"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"j26Dz86kjNdx","executionInfo":{"status":"error","timestamp":1711201564458,"user_tz":-330,"elapsed":1773,"user":{"displayName":"Pratham Kumbhare","userId":"15480860471760659832"}},"outputId":"60a2f89e-59b8-4852-d97b-a9842249c9b8"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"slice indices must be integers or None or have an __index__ method","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-20d4210394bd>\u001b[0m in \u001b[0;36m<cell line: 201>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mkfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mbootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-20d4210394bd>\u001b[0m in \u001b[0;36mkfold\u001b[0;34m(data, k)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrainingData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"]}],"source":["\n","import csv\n","from collections import defaultdict\n","import pydotplus\n","import pandas as pd\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.utils import resample\n","from sklearn.utils import shuffle\n","\n","\n","class DecisionTree:\n","    def __init__(self, col=-1, value=None, trueBranch=None, falseBranch=None, results=None, summary=None):\n","        self.col = col\n","        self.value = value\n","        self.trueBranch = trueBranch\n","        self.falseBranch = falseBranch\n","        self.results = results\n","        self.summary = summary\n","\n","\n","def kfold(data,k):\n","\n","    X= shuffle(data,random_state=42)\n","    X=X.to_numpy()\n","    n = len(data)/k\n","    if(n>int(n)):\n","        n= (int(n)+1)\n","    trainingData = X[0:n*(k-1)]\n","    test = X[n*(k-1):len(data)]\n","\n","    testData = test[:,:test.shape[1]-1]\n","    y_test = test[:,test.shape[1]-1:]\n","    decisionTree = growTree(trainingData, evaluationFunction=gini)\n","    prune(decisionTree, 0.8, notify=True)\n","    count=0\n","    count1=0\n","    true=[]\n","    pred=[]\n","    for i in range(testData.shape[0]):\n","        count1 +=1\n","        t = classify(testData[i], decisionTree)\n","        for key, value in t.items():\n","\n","            pred.append(key)\n","            true.append(y_test[i])\n","            if(key==y_test[i]):\n","                count +=1\n","\n","    print(\"\\nPredictive accuracy for k = \",k,\" is \",count/count1)\n","    print(confusion_matrix(true,pred))\n","    a,b,c,d = precision_recall_fscore_support(true, pred, average=\"macro\")\n","    print(\"Precision = \",a, \"\\nRecall = \",b,\" \\nF1-score = \",c)\n","\n","\n","def bootstrap(data,n):\n","    data = data.to_numpy()\n","    for j in range(n):\n","        trainingData = resample(data,n_samples=250)\n","        testData = resample(data,n_samples=50)\n","        y_test = testData[:,testData.shape[1]-1:]\n","        testData = testData[:,:testData.shape[1]-1]\n","        decisionTree = growTree(trainingData, evaluationFunction=gini)\n","        prune(decisionTree, 0.8, notify=True)\n","        count=0\n","        count1=0\n","        true=[]\n","        pred=[]\n","        for i in range(testData.shape[0]):\n","            count1 +=1\n","            t = classify(testData[i], decisionTree)\n","            for key, value in t.items():\n","\n","                pred.append(key)\n","                true.append(y_test[i])\n","                if(key==y_test[i]):\n","                    count +=1\n","\n","        print(\"\\nPredictive accuracy for Bootstrap = \",j+1,\" is \",count/count1)\n","        print(confusion_matrix(true,pred))\n","        a,b,c,d = precision_recall_fscore_support(true, pred, average='macro')\n","        print(\"Precision = \",a, \"\\nRecall = \",b,\"\\nF1-score = \",c)\n","\n","\n","def Unique_Counts(rows):\n","    results_ = {}\n","    for row in rows:\n","        r = row[-1]\n","        if r not in results_: results_[r] = 0\n","        results_[r] += 1\n","    return results_\n","\n","\n","def entropy(rows):\n","    from math import log\n","    log2 = lambda x: log(x)/log(2)\n","    results_ = Unique_Counts(rows)\n","    entropy_value = 0.0\n","    for r in results_:\n","        prob = float(results_[r])/len(rows)\n","        entropy_value -= prob*log2(prob)\n","    return entropy_value\n","\n","\n","def divideSet(trows, column_, val):\n","    splitFn = None\n","    if isinstance(val, int) or isinstance(val, float):\n","        splitFn = lambda row : row[column_] >= val\n","    else:\n","        splitFn = lambda row : row[column_] == val\n","\n","    lista = [row for row in trows if splitFn(row)]\n","    listb = [row for row in trows if not splitFn(row)]\n","    return (lista, listb)\n","\n","\n","def gini(trows):\n","    total = len(trows)\n","    count = Unique_Counts(trows)\n","    imp_val = 0.0\n","\n","    for ka in count:\n","        pa = float(count[ka])/total\n","\n","        for kb in count:\n","            if ka == kb: continue\n","            pb = float(count[kb])/total\n","            imp_val += (pa*pb)\n","\n","    return imp_val\n","\n","\n","def growTree(rows, evaluationFunction=entropy):\n","    if len(rows) == 0: return DecisionTree()\n","    currScore = evaluationFunction(rows)\n","\n","    gain_best = 0.0\n","    bestAttribute = None\n","    bestSets = None\n","\n","    columnCount = len(rows[0]) - 1\n","    for col_ in range(0, columnCount):\n","        columnValues = [row_[col_] for row_ in rows]\n","        lsUnique = list(set(columnValues))\n","\n","        for value in lsUnique:\n","            (seta, setb) = divideSet(rows, col_, value)\n","\n","            prob = float(len(seta)) / len(rows)\n","            gain = currScore - prob*evaluationFunction(seta) - (1-prob)*evaluationFunction(setb)\n","            if gain>gain_best and len(seta)>0 and len(setb)>0:\n","                gain_best = gain\n","                bestAttribute = (col_, value)\n","                bestSets = (seta, setb)\n","\n","    dcY = {'impurity' : '%.3f' % currScore, 'samples' : '%d' % len(rows)}\n","    if gain_best > 0:\n","        trueBranch = growTree(bestSets[0], evaluationFunction)\n","        falseBranch = growTree(bestSets[1], evaluationFunction)\n","        return DecisionTree(col=bestAttribute[0], value=bestAttribute[1], trueBranch=trueBranch,\n","                            falseBranch=falseBranch, summary=dcY)\n","    else:\n","        return DecisionTree(results=Unique_Counts(rows), summary=dcY)\n","\n","\n","def prune(tree, minGain, evaluationFunction=entropy, notify=False):\n","\n","    if tree.trueBranch.results == None: prune(tree.trueBranch, minGain, evaluationFunction, notify)\n","    if tree.falseBranch.results == None: prune(tree.falseBranch, minGain, evaluationFunction, notify)\n","\n","    if tree.trueBranch.results != None and tree.falseBranch.results != None:\n","        ta, fa = [], []\n","\n","        for v_, c_ in tree.trueBranch.results.items(): ta += [[v_]] * c_\n","        for v_, c_ in tree.falseBranch.results.items(): fa += [[v_]] * c_\n","\n","        prob = float(len(ta)) / len(ta + fa)\n","        delta_val = evaluationFunction(ta+fa) - prob*evaluationFunction(ta) - (1-prob)*evaluationFunction(fa)\n","        if delta_val < minGain:\n","            tree.trueBranch, tree.falseBranch = None, None\n","            tree.results = Unique_Counts(ta + fa)\n","\n","\n","def classify(obs, tree):\n","\n","    def classify_(obs, tree):\n","        if tree.results != None:\n","            return tree.results\n","        else:\n","            val = obs[tree.col]\n","            branch_ = None\n","            if isinstance(val, int) or isinstance(val, float):\n","                if val >= tree.value: branch_ = tree.trueBranch\n","                else: branch_ = tree.falseBranch\n","            else:\n","                if val == tree.value: branch_ = tree.trueBranch\n","                else: branch_ = tree.falseBranch\n","        return classify_(obs, branch_)\n","\n","    return classify_(obs, tree)\n","\n","\n","if __name__ == '__main__':\n","        from sklearn.metrics import confusion_matrix\n","\n","        #dataset in the same directory as the code file\n","        data=pd.read_csv(\"Soybean.csv\",header=None,index_col=None)\n","        target = data.iloc[:,0]\n","        data = data.drop(data.columns[0],axis = 1)\n","        data = data.assign(target1=target)\n","        data.columns = range(data.shape[1])\n","\n","        for i in range(2,13):\n","            kfold(data,i)\n","        bootstrap(data,1)\n"]}]}